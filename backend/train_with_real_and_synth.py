#!/usr/bin/env python3
"""
Train using realistic synthetic domains + actual dataset from backend/dataset.

This script will:
 - Read all .xlsx files under backend/dataset (recursively)
 - Try to detect a URL/domain column and a label/ground-truth column
 - Normalize labels into: 'Phishing', 'Suspected' (or 'Legitimate')
 - Combine the real domains with synthetic domains generated by EnhancedPhishingDetector
 - Extract 51 features and train the PyTorch model

Run: python backend/train_with_real_and_synth.py
"""

import os
import glob
import pandas as pd
import tldextract
from collections import Counter

from enhanced_pytorch_model_fixed import EnhancedPhishingDetector


def find_excel_files(dataset_root: str):
    pattern = os.path.join(dataset_root, '**', '*.xlsx')
    return glob.glob(pattern, recursive=True)


def detect_columns(df: pd.DataFrame):
    cols = [c.lower() for c in df.columns]
    url_col = None
    label_col = None

    # heuristics for url column
    for candidate in ['url', 'domain', 'website', 'site', 'link', 'fqdn']:
        for c in df.columns:
            if candidate in c.lower():
                url_col = c
                break
        if url_col:
            break

    # heuristics for label column
    for candidate in ['label', 'ground', 'ground_truth', 'class', 'gt', 'category', 'type']:
        for c in df.columns:
            if candidate in c.lower():
                label_col = c
                break
        if label_col:
            break

    return url_col, label_col


def extract_domain_from_url(u: str):
    try:
        if pd.isna(u):
            return None
        s = str(u).strip()
        # if looks like a plain domain without scheme, tldextract still works
        ext = tldextract.extract(s)
        if ext.domain and ext.suffix:
            return f"{ext.domain}.{ext.suffix}".lower()
        # fallback: return original
        return s.lower()
    except Exception:
        return None


def normalize_label(v):
    if pd.isna(v):
        return 'Suspected'
    s = str(v).strip().lower()
    if any(k in s for k in ['phish', 'phishing', 'malicious', 'bad', 'spear']):
        return 'Phishing'
    if any(k in s for k in ['legit', 'benign', 'legitimate', 'good']):
        return 'Suspected'
    # numeric codes
    try:
        iv = int(float(s))
        # common convention: 0 legit, 1 suspicious, 2 phishing (varying)
        if iv == 2:
            return 'Phishing'
        if iv == 1:
            return 'Suspected'
        if iv == 0:
            return 'Suspected'
    except Exception:
        pass

    # default guess: if contains 'sus' or 'leg' mark as Suspected, else Phishing if contains negative words
    if any(k in s for k in ['suspect', 'suspicious', 'susp']):
        return 'Suspected'

    return 'Phishing' if len(s) > 0 and 'phish' in s else 'Suspected'


def load_real_dataset(dataset_root: str):
    files = find_excel_files(dataset_root)
    print(f"Found {len(files)} Excel files under {dataset_root}")
    domains = []
    labels = []

    for f in files:
        try:
            df = pd.read_excel(f)
            print(f"Reading {f} with columns: {list(df.columns)} | rows: {len(df)}")
            url_col, label_col = detect_columns(df)
            if url_col is None:
                print(f"  - No URL/domain column detected in {f}; skipping")
                continue

            if label_col is None:
                # try to see if there's a separate sheet or columns containing 'ground'
                print(f"  - No label column detected in {f}; attempting to infer labels or skip")

            for _, row in df.iterrows():
                d = extract_domain_from_url(row[url_col])
                if not d:
                    continue
                if label_col:
                    lab = normalize_label(row[label_col])
                else:
                    # If no label column, try to infer from filename heuristics
                    # e.g., filenames containing 'phish' or 'legit'
                    fname = os.path.basename(f).lower()
                    if 'phish' in fname:
                        lab = 'Phishing'
                    else:
                        lab = 'Suspected'

                domains.append(d)
                labels.append(lab)

        except Exception as e:
            print(f"  - Error reading {f}: {e}")
            continue

    print(f"Loaded {len(domains)} labeled domains from real dataset")
    return domains, labels


def main():
    dataset_root = os.path.join('backend', 'dataset')

    detector = EnhancedPhishingDetector()

    # Load real dataset
    real_domains, real_labels = load_real_dataset(dataset_root)

    if len(real_domains) == 0:
        print("No real domains found â€” falling back to purely synthetic training")
        results = detector.run_complete_training()
        print(results)
        return

    # Generate synthetic data proportionate to real data
    synth_size = max(1000, int(len(real_domains) * 2))
    synth_domains, synth_labels = detector.create_realistic_synthetic_domains(num_samples=synth_size)

    # Combine datasets
    combined_domains = list(real_domains) + list(synth_domains)
    combined_labels = list(real_labels) + list(synth_labels)

    print(f"Combined dataset sizes: real={len(real_domains):,}, synth={len(synth_domains):,}, total={len(combined_domains):,}")

    # Extract features for combined set
    X = detector.extract_51_features(combined_domains)

    # Train-test split and model training will expect labels aligned with X order
    # We pass labels as parallel list
    # Use internal train_pytorch_model and evaluate
    # Split inside detector.train_pytorch_model already uses train_test_split, so call it directly
    training_results = detector.train_pytorch_model(X, combined_labels, epochs=80)

    # Evaluate on held-out split by reusing train_test_split to get a test portion
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(
        X, combined_labels, test_size=0.2, random_state=42,
        stratify=[1 if 'phishing' in str(l).lower() else 0 for l in combined_labels]
    )

    eval_results = detector.evaluate_model(X_test, y_test)

    detector.save_model(filepath='enhanced_pytorch_phishing_model_combined.pkl')

    print('\nFinal results:')
    print(training_results)
    print(eval_results)


if __name__ == '__main__':
    main()
